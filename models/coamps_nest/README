# DART software - Copyright UCAR. This open source software is provided
# by UCAR, "as is", without charge, subject to all terms of use at
# http://www.image.ucar.edu/DAReS/DART/DART_download
#
# DART $Id$

An updated version of the coamps model interfaces and scripts.
Contributed by Alex Reinecke, NRL, Monterey.

The primary differences from the original coamps model code are:

 - the ability to assimilate nested domains
 - assimilates real observations
 - a simplified way to specify the state vector
 - I/O COAMPS data files 
 - extensive script updates to accommodate additional HPC environments


June 2017 ... updating to the rma_trunk ... 

When Tim H. (me) asked if the hdf5 files contain three nuisance variables :
'THBM','EXBM', and 'EXBW'  Sasa replied: 
 
They certainly do not contain EXBM and EXBW.
Here is the way forward (assuming we have variables on sigma levels for DART to operate on):
 
Exner:
1) In `coamps_nest/shell_scripts' is a shell script `create_coamps_intrinsic_mod.sh'
2) It will write Fortran code, `coamps_intrinsic_mod.f90'
3) In this code, there is a subroutine that calculates mean Exner on sigma levels 
   (`define_mean_exner'). Since sigma levels are thermodynamic levels (`M'), 
   we now have base state Exner_M.
4) One of the variables on sigma levels, `perprs' is Exner perturbation. 
   If we add it to mean state Exner_M we get full Exner on M levels.
5) Exner on W levels is linearly interpolated from values on M levels. 
   Caveat, at the surface and TOA extrapolation must be used.
 
Potential temperature:
1) Just grab `pottmp' on sigma levels: it already contains full potential temperature.
 
I hope it makes sense, please let me know if you need further clarifications or help.
 
sa#a


Sasa: Here's the scoop:
 
1) A shell script (shell_scripts/populate_state_vars.sh) will write the file state.vars
2) It needs a template to run (EXPERIMENTS_EXAMPLE/state.dat
3) To run it, simply change directory to EXPERIMENTS_EXAMPLE, change the number of levels to reflect the actual number of levels (40->60 and 41->61, I believe), and run the script ../../shell_scripts/populate_state_vars.sh state.dat true
4) You should end up with state.vars file


Thu Sep 14 15:31:00 MDT 2017 $Revision$:
 The problem I (Tim H) was having was with the DART add_domain() call, 
it expects the variables to exist in the source file. They do not. 
I spent a lot of time trying to work around the problem to no avail. 
I resurrected the trans_coamps_to_dart.f90 and modified it to read 
an HDF file, calculate the nuisance variables and write them to 
a netCDF file.  There are two instances of the state_vector structure 
- one for the DART state, and one for the entire COAMPS state.  The 
coamps structure does not actually allocate any space for the state, 
but does have the variable names we want - except for the nuisance variables.


-------------------------------------------------------------------------------
Mon Nov 13 12:51:13 PST 2017 - conf call with Sasa, Sergey

*) What fields in the HDF5 file are used for restarting - hop test material?
    which tau do we use comes from ktauf

*) Where do the observations come from? 'Innovations' ... from what?

*) Do you want to use the DART forward operators or the ones defined in obs_def_navdas_mod.f90 - they use non-standard observation types - and there is a clash with the get_expected_altimeter() function

*) time ... what is going on with the 'model_mod: get_dart_time' ... is cdtg always from the convert.nml

*) the default perturb routine needs to be swapped out for the coamps_pert_mod:perturb_state routine

*) go over scripting

*) exner functions ... inflation/perturbation nomenclature ... are these 'mean variables' seems like coamps_intrinsic_mod.f90 defines them based on the standard atmosphere - so they are never changing - is that true?

*) what are assumptions about what needs to be staged to advance coamps till next observation time

*) Meeting with Tim W. indicated the fields in the hdf5 file may be 'unstaggered'.
   if we update the 'fcstfld' or 'analfld' ... what does coamps use to restart?
   Do we use the variables in the hdf5 file or do we use the routines based on
   the input parameters (which are alread in use for the model_interpolate code
   that takes into account the variable stagger - but get_state_meta_data does not,
   so the localization distances are off).
   coamps_interp_mod:extract_neighbors() 
U(1) is EAST of first mass point, V(1) is NORTH first mass point

*) the coamps_netcdf_mod:nc_write_prognostic_atts() routine writes out stuff I do not believe 
   to be correct given the staggering uncertainty ... I will remove this as soon as the scripting is done

*) model_mod_check on eddy with PG compiler: -- TEST 2 -- Read and write restart file
0: DEALLOCATE: memory at (nil) not allocated


-------------------------------------------------------------------------------
Tue Nov 28 09:55:48 PST 2017

Frolov, Dr. Sergey
Nov 15 (13 days ago)

"Tim,
In case you want to see an example of the innovation file for this DTG and domain.
Eddy in /home/nopp/COAMPS_hdf5_files
 
Innovation file innov_a_2013011000
Some description of this format is in “Innovation Vector Description.pdf”
However, it is not the exact description. This document is actually for a related system 
that produces this innovation vector. You can pretty much ignore all the stuff about the radiances.
 
Matlab program to read the file is in rd_ainv.m
In matlab
[n ob bk t_bk iv err etc lat lon p vty ity nvp chk dt pf org idp rh_bk] = rd_ainv(fn);"

Tim: updated the instru_list_coamps.inc based on new table (Sergey got me one from Pat Pauley)
and was able to read the innov_a_2013011000 file. It had instruments not in the .inc file
and highlighted a problem in the navdas_innov_mod.f90
I also replaced the calls to 'insert_obs_in_sequence()' with 'add_obs_to_seq()' which
does not do an exhaustive search through the sequence to insert at proper time. The (optimized) run-time
went from almost 700 seconds to 14 seconds. Also added the 'ngt' filename to the input.nml.
'ngt' appears to be something related to vortex locations - should get a much better name ...

-------------------------------------------------------------------------------
Mon Dec 18 09:42:42 PST 2017

0) assimilation of two simple synthetic observations works as expected.
1) innovation observation file conversion supported. Have not run it through filter.
   those forward operators are appropriate for the existing obs_def_navdas_mod.f90,
   apparently has potential temperature as part of the state. Do we want to convert
   potential temperature to sensible temperature up-front - so we can use any/all other
   DART observation converters? Would require converting back after assimilation.
2) creating an initial ensemble ... TBD ... Tim W. had several ideas on how to perturb
   a single state to generate an ensemble.  ball is in NRL's hands.
3) Not sure how to test vertical conversion ... (re-engage Nancy?)
4) Firm up the mechanism to convey the fcstfld being read and then updating the analfld 
   to be used as the starting point for the next forecast cycle.  Sergey indicated an
   entirely new hdf5 file is appropriate ... 
5) scripting is updated as far as I can take it without actually being able to advance
   coamps ...

-------------------------------------------------------------------------------
Thu Mar  1 08:33:38 PST 2018

Sergey provided these files.
He had an 80 member ensemble experiment in the Med, but the files were binary.
He converted a subset of the variables to hdf5 for me ... not sure the DTG in the file
matches the DTG in the variables. Not all variables 'naturally' present in the native
HDF5 files are present in these.

0[308] eddy:~/COAMPS_hdf5_files/MedEnsemble $ h5ls coamps_0001_2012010100.hdf5
airtmp_sig_031050_000010_1a0067x0037_2012010100_00060000_fcstfld Dataset {30, 37, 67}
datahd_sfc_000000_000000_1a2000x0001_2012010100_00000000_infofld Dataset {2000, 1}
perprs_sig_031050_000010_1a0067x0037_2012010100_00060000_fcstfld Dataset {30, 37, 67}
pottmp_sig_031050_000010_1a0067x0037_2012010100_00060000_fcstfld Dataset {30, 37, 67}
uuwind_sig_031050_000010_1a0067x0037_2012010100_00060000_fcstfld Dataset {30, 37, 67}
uuwind_zht_000010_000000_1a0067x0037_2012010100_00060000_fcstfld Dataset {1, 37, 67}
vvwind_sig_031050_000010_1a0067x0037_2012010100_00060000_fcstfld Dataset {30, 37, 67}
vvwind_zht_000010_000000_1a0067x0037_2012010100_00060000_fcstfld Dataset {1, 37, 67}
wvapor_sig_031050_000010_1a0067x0037_2012010100_00060000_fcstfld Dataset {30, 37, 67}
wwwind_sig_034800_000000_1a0067x0037_2012010100_00060000_fcstfld Dataset {31, 37, 67}

Running Darth_Test/run_filter.csh made headway, but the forward operators all failed.

0[389] eddy:~/thoar_eddy1/Darth_Test/instance_0001 $ h5ls coamps_0001_2012010606.hdf5
airtmp_sig_031050_000010_1a0067x0037_2012010606_00060000_fcstfld Dataset {30, 37, 67}
datahd_sfc_000000_000000_1a2000x0001_2012010606_00000000_infofld Dataset {1, 2000}
perprs_sig_031050_000010_1a0067x0037_2012010606_00060000_fcstfld Dataset {30, 37, 67}
pottmp_sig_031050_000010_1a0067x0037_2012010606_00060000_fcstfld Dataset {30, 37, 67}
terrht_sfc_000000_000000_1a0067x0037_2012010606_00000000_fcstfld Dataset {37, 67}
uuwind_sig_031050_000010_1a0067x0037_2012010606_00060000_fcstfld Dataset {30, 37, 67}
uuwind_zht_000010_000000_1a0067x0037_2012010606_00060000_fcstfld Dataset {37, 67}
vvwind_sig_031050_000010_1a0067x0037_2012010606_00060000_fcstfld Dataset {30, 37, 67}
vvwind_zht_000010_000000_1a0067x0037_2012010606_00060000_fcstfld Dataset {37, 67}
wvapor_sig_031050_000010_1a0067x0037_2012010606_00060000_fcstfld Dataset {30, 37, 67}
wwwind_sig_034800_000000_1a0067x0037_2012010606_00060000_fcstfld Dataset {31, 37, 67}

After assimilation , 'trans_dart_to_coamps' uses COAMPS write routines that expect a
DTG in the file name, the dart call provides the base filename of 'CoampsUpdate'

0[382] eddy:~/thoar_eddy1/Darth_Test/instance_0001 $ h5ls CoampsUpdate_2012010612.hdf5
perprs_sig_031050_000010_1a0067x0037_2012010606_00000000_analfld Dataset {30, 37, 67}
pottmp_sig_031050_000010_1a0067x0037_2012010606_00000000_analfld Dataset {30, 37, 67}
uuwind_sig_031050_000010_1a0067x0037_2012010606_00000000_analfld Dataset {30, 37, 67}
uuwind_zht_000010_000000_1a0067x0037_2012010606_00000000_analfld Dataset {37, 67}
vvwind_sig_031050_000010_1a0067x0037_2012010606_00000000_analfld Dataset {30, 37, 67}
vvwind_zht_000010_000000_1a0067x0037_2012010606_00000000_analfld Dataset {37, 67}
wvapor_sig_031050_000010_1a0067x0037_2012010606_00000000_analfld Dataset {30, 37, 67}
wwwind_sig_034800_000000_1a0067x0037_2012010606_00000000_analfld Dataset {31, 37, 67}

-------------------------------------------------------------------------------

conference call today ... Sasha, Jim D., Andy

a) Sasha will create an initial 20-member ensemble for the WC domain using a perturbed physics
   approach - then forecast for 12 hours. A single mesh.
b) Jim/Sasha will provide a routine to go to/from their sigma coordinates to pressure so
   that we can convert the model state (and obs) to pressure for assimilation.
a + b have a target delivery date of August 9th.

c) given a forecast file (coamps_0001_2012010606.hdf5) with variables 
(airtmp_sig_031050_000010_1a0067x0037_2012010606_00060000_fcstfld) the DTG is 2012010606, the TAU is 00060000
After assimilation the filename (CoampsUpdate_2012010612.hdf5) should have variables
(airtmp_sig_031050_000010_1a0067x0037_2012010612_00000000_analfld)

d) I need to become familiar with converting 'everything' (state/obs) to the assimilation vertical coordinate.
   Should be able to get a single assimilation cycle going with our conventional obs.

e) NRL will be responsible for cycling the system to flush out any bugs in the assimilation framework.


# <next few lines under version control, do not edit>
# $URL$
# $Revision$
# $Date$

