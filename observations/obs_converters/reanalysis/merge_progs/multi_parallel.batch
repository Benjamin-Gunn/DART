#!/bin/ksh 
#
# DART software - Copyright 2004 - 2013 UCAR. This open source software is
# provided by UCAR, "as is", without charge, subject to all terms of use at
# http://www.image.ucar.edu/DAReS/DART/DART_download
#
# DART $Id: multi_parallel.lsf 9948 2016-03-03 22:30:57Z nancy $
#
#--------------------------------------------------------------
# DESCRIPTION:
# Merge NCEP BUFR obs (inc ACARS), GPS RO obs, and AIRS T/Q obs.
#
# This script merges a set of input obs files into 6-hour files.  
# Each file is named by the center time of the data and uses
# the CESM time convention for the name format.  For example, 
# a file with a name ending in YYYY-MM-DD-21600 will contain data
# starting at 03:00:01Z and ending at 09Z.  Note that a file
# with a name ending in YYYY-MM-DD-00000 contains data from
# 21:00:01Z the previous day to 03Z of the day YYYY-MM-DD.
#
# this version assumes the NCEP+ACARS input files were created
# as 6H files with filenames ending in 06, 12, 18, 00.
# it assumes daily GPS obs, and daily AIRS obs.
#
# be *very* careful to check that you have the right files for the
# first and last day -- many datasets that are distributed as collections 
# of weekly or monthly files, and you cannot generate obs for midnight
# on days where you don't have the previous day's data.
#
# Driver script for the parallel version.  Submit this script
# to your batch system and it will invoke the 'domerge.sh'
# script once for each conversion day.
#
# this one does N conversions in parallel from a command script.
#
# TODO: this script should call the mergeit6h.sh, 3h or 1h files.
# right now it basically has the 6h script embedded in it.
# it should have each line in the command file do one day's worth
# of conversions.  the merge scripts should take command line args
# for start/end dates/times and then loop over that time period.
# this script should start N merge script calls, and each one can
# merge as many time periods as seems efficient.
#
# note that since we're using advance_time and obs_sequence_tool
# and these are compiled executable programs, if we run on different 
# hardware (e.g. cheyenne vs casper) we will need to build 
# executables for that specific machine and run those.
# in the past i've done this two different ways.  one way is
# to use symbolic links to the right machine versions and
# keep the same names in this script.  or i've made subdirs to
# hold the executables for different machines and then made the
# executable calls include a machine name.  look for EXEDIR in 
# this script; it looks like i'm using the second approach here.
#
#--------------------------------------------------------------

#==========================================================================
# SLURM directives             sbatch script.csh
#
# sinfo     information about the whole slurm system
# squeue    information about running jobs
# sbatch    submit a job
# scancel   kill a job
#
#SBATCH --ignore-pbs
#SBATCH --job-name=mergeob1
#SBATCH -n 36
#SBATCH --ntasks-per-node=36
#SBATCH --time=04:10:00
#SBATCH -A P86850054
#SBATCH -p dav
#SBATCH -C casper
#SBATCH -e merge1.%j.err
#SBATCH -o merge1.%j.out
#
#==========================================================================
# PBS directives                qsub script.csh
#
# qstat    information on running jobs
# qsub     submit a job
# qdel     kill a job
# qpeek    see output from a running job
#
#PBS -N mergeob1         
#PBS -l walltime=04:00:00
#PBS -q regular
#PBS -l select=1:ncpus=36:mpiprocs=36
#PBS -A P86850054
#
#==========================================================================
# LSF directives                bsub < script.csh
#
# bstat    information on running jobs
# bsub     submit a job
# bdel     kill a job
# bpeek    see output from a running job
#
#BSUB -J mergeob1
#BSUB -o mergeob1.%J.log
#BSUB -q small
#BSUB -n 16
#BSUB -W 0:10:00
#BSUB -P P86850054
#
#==========================================================================

# USER SETTINGS HERE

#--------------------------------------------------------------

# set the first and last days/hours.  can roll over month and year boundaries.
# if start_hour is 12Z and step is 6H, then the first file will be centered 
# at 12Z on this day, with data starting at 9Z and ending at 15Z.
#
# set these WITHOUT leading 0s.  they are numeric values, not strings.
#
# if you set the start hour to 0, you must have data files for
# the day immediately preceeding this date.
#
# on cheyenne, this is taking about 2 hours for a month
# in serial, about 5 mins in parallel.
#
# on casper with 36 tasks this merged a year of obs in an hour.

let start_year=2019
let start_month=12
let start_day=1
let start_hour=0

let end_year=2020
let end_month=1
let end_day=2
let end_hour=0


# string to control the number of hours in each file.
# set the forward and backwards half steps to be consistent.
# (the +1s will be done when setting the namelist seconds)
step='+6h'
halfstep='+3h'
halfback='-3h'

# should match the mpiprocs=X setting above
let njobs=36

# END USER SETTINGS


TMPDIR=/glade/scratch/$USER/temp
EXEDIR=.

# set things that vary between batch systems here.

if [ "$SLURM_JOB_ID" != "" ] ; then
  echo running SLURM
  SLURM=true
  RUNCMD="/usr/local/bin/srun --multi-prog"
  EXEDIR=casper
  # i do not know why $USER is undefined.
  TMPDIR=/glade/scratch/$SLURM_JOB_USER/temp
elif [ "$PBS_NODEFILE" != "" ] ;  then
  echo running PBS
  PBS=true
  export MPI_SHEPHERD=true
  RUNCMD="mpiexec_mpt launch_cf.sh"
elif [ "$LSB_HOSTS" != "" ] ; then
  echo running LSF
  LSF=true
  export MP_PGMMODEL=mpmd
  RUNCMD="mpirun.lsf -cmdfile"
  EXEDIR=ibm  
else
  echo running without a batch system
  NOBATCH=true
  RUNCMD="csh"
fi

mkdir -p $TMPDIR

echo job started at `date`
echo


# before running advance_time there must be an input.nml
# with at least a utilities namelist.  it will be overwritten
# in the first real loop by the input.nml.template, so make
# any permanent changes the template and not to input.nml.

rm -f input.nml
echo '&utilities_nml' > input.nml
echo '/' >> input.nml

# convert the start and stop times to gregorian days, so we can
# compute total number of days including rolling over month and
# year boundaries.  make sure all values have leading 0s if they
# are < 10.  do the end time first so we can use the same values
# to set the initial day while we are doing the total day calc.

# the output of advance time with the -g input is:
#   gregorian_day_number  seconds
# use ${var[0]} to return the day number, ${var[1]} for the seconds

mon2c=`printf %02d $end_month`
day2c=`printf %02d $end_day`
hor2c=`printf %02d $end_hour`
endstring=${end_year}${mon2c}${day2c}${hor2c}
#echo endstring $endstring
set -A end_t `echo $endstring 0 -g | $EXEDIR/advance_time`

#echo end_t $end_t

mon2c=`printf %02d $start_month`
day2c=`printf %02d $start_day`
hor2c=`printf %02d $start_hour`
startstring=${start_year}${mon2c}${day2c}${hor2c}
#echo startstring $startstring
set -A start_t `echo $startstring 0 -g | $EXEDIR/advance_time`

#echo start_t $start_t

# count up how many steps we are going to be executing

curtime=$startstring
let totalsteps=0

while true ; do

  # compute the current gregorian day here.  
  #  this_t[0] is day, this_t[1] is seconds
  set -A this_t `echo $curtime 0 -g | $EXEDIR/advance_time`

#echo this_t $this_t
  # if the current day is beyond the end day, we are done.  break out of loop.
  # if the current day is equal to end day, check the seconds to see if we quit.
  # otherwise, do the loop again.
  if [[ ${this_t[0]} -gt ${end_t[0]} ]] ; then break ; fi
  if [[ ${this_t[0]} -eq ${end_t[0]}  &&  ${this_t[1]} > ${end_t[1]} ]] ; then break ; fi

  # advance to the next time and increment the step count
  curtime=`echo $curtime $step | $EXEDIR/advance_time`
  let totalsteps=$totalsteps+1
done



echo This script is going to create $totalsteps DART obs sequence files.
echo Starting at $start_year $start_month $start_day $start_hour
echo Ending at $end_year $end_month $end_day $end_hour
echo

# the output of this call is a string YYYYMMDDHH
# see below for help in how to easily parse this up into words
  curstep=`echo $startstring         0 | $EXEDIR/advance_time`
 nextstep=`echo $startstring     $step | $EXEDIR/advance_time`
stepstart=`echo $startstring $halfback | $EXEDIR/advance_time`
  stepend=`echo $startstring $halfstep | $EXEDIR/advance_time`

#echo before loop
#echo curstep nextstep stepstart stepend 
#echo $curstep $nextstep $stepstart $stepend 

# ok, let's actually do something.  up to now it has
# been computing fiddly time bits.

let s=1
while [[ $s -le $totalsteps ]] ; do

  rm -f mycmdfile

  let j=1
  while [[ $j -le $njobs && $s -le $totalsteps ]] ; do

    # parse out the parts from a string which is YYYYMMDDHH
    # use cut with the byte option to pull out columns 1-4, 5-6, 7-8, and 9-10
    # c = current middle-of-step, n = next middle, ss = step start, se = step end
  
     cyear=`echo $curstep | cut -b1-4`
    cmonth=`echo $curstep | cut -b5-6`
      cday=`echo $curstep | cut -b7-8`
     chour=`echo $curstep | cut -b9-10`
  
     nyear=`echo $nextstep | cut -b1-4`
    nmonth=`echo $nextstep | cut -b5-6`
      nday=`echo $nextstep | cut -b7-8`
     nhour=`echo $nextstep | cut -b9-10`
  
    ssyear=`echo $stepstart | cut -b1-4`
   ssmonth=`echo $stepstart | cut -b5-6`
     ssday=`echo $stepstart | cut -b7-8`
    sshour=`echo $stepstart | cut -b9-10`
  
    seyear=`echo $stepend | cut -b1-4`
   semonth=`echo $stepend | cut -b5-6`
     seday=`echo $stepend | cut -b7-8`
    sehour=`echo $stepend | cut -b9-10`
  
    # compute the equivalent gregorian days/secs here.
    set -A g `echo ${cyear}${cmonth}${cday}${chour} 0 -g | $EXEDIR/advance_time`
    cgregday=${g[0]}; cgregsec=${g[1]}
  
    # special for dart: step start needs to be +1 second 
    set -A g `echo ${ssyear}${ssmonth}${ssday}${sshour} +1s -g | $EXEDIR/advance_time`
    ssgregday=${g[0]}; ssgregsec=${g[1]}
  
    set -A g `echo ${seyear}${semonth}${seday}${sehour} 0 -g | $EXEDIR/advance_time`
    segregday=${g[0]}; segregsec=${g[1]}
  
    # compute the CESM-style time string for the output filename
    cesmtime=`echo ${cyear}${cmonth}${cday}${chour} 0 -c | $EXEDIR/advance_time`
  
    # compute the DOYs, and make sure they're 3 digits long
    set -A jan1 `echo ${cyear}010100 0 -g | $EXEDIR/advance_time`
    let cdy=${cgregday}-${jan1[0]}+1
    cdoy=`printf %03d $cdy`
  
    set -A jan1 `echo ${ssyear}010100 0 -g | $EXEDIR/advance_time`
    let ssdy=${ssgregday}-${jan1[0]}+1
    ssdoy=`printf %03d $ssdy`
  
    set -A jan1 `echo ${seyear}010100 0 -g | $EXEDIR/advance_time`
    let sedy=${segregday}-${jan1[0]}+1
    sedoy=`printf %03d $sedy`
    
    # status/debug - comment in or out as desired.
#    echo "starting processing for "  ${cyear}  ${cmonth}  ${cday}  ${chour}, gregorian day/sec:  $cgregday  $cgregsec, DOY $cdoy 
#    echo "          step start is " ${ssyear} ${ssmonth} ${ssday} ${sshour}, gregorian day/sec: $ssgregday $ssgregsec, DOY $ssdoy 
#    echo "            step end is " ${seyear} ${semonth} ${seday} ${sehour}, gregorian day/sec: $segregday $segregsec, DOY $sedoy 
#    echo 
  
  
    # construct often-used strings below
       ym=${cyear}${cmonth}   ;   ymd=${ym}${cday}      ;   ymdh=${ymd}${chour}
     ssym=${ssyear}${ssmonth} ; ssymd=${ssym}${ssday}   ; ssymdh=${ssymd}${sshour}
     seym=${seyear}${semonth} ; seymd=${seym}${seday}   ; seymdh=${seymd}${sehour}
  
#  #echo
#  echo     ym=$ym ; echo   ymd=${ymd}   ; echo   ymdh=${ymdh}
#  echo   ssym=$ym ; echo ssymd=${ssymd} ; echo ssymdh=${ssymdh}
#  echo   seym=$ym ; echo seymd=${seymd} ; echo seymdh=${seymdh}
#  echo
  
    # ----------------------------------------
    # start of this merge-specific code
  
    # add whatever input observation files you need to the 'olist' file.
    # that sets the input for the merge.  do not list the same file twice or
    # those obs will be silently duplicated.  todo: could put in a 'sort|uniq'
    # to catch that.
  
    rm -f olist
  
    # the base NCEP + ACARS - 3Z to 3Z ; use the mid time to
    # get the right filename.  since these are already 6h files
    # we will only every need one.
    ls /glade/p/cisl/dares/Observations/NCEP+ACARS/${ym}_6H/obs_seq${ymdh} >> olist
  
    # GPS (local operator)  
    #  old files were - 06,12,18,24 +/- 3H, and named obs_seq.gpsroYYYYMMMDDHH
    #  new files are 0Z to 0Z, daily, and named obs_seq.gpsro_YYYYMMDD
    #  for 0Z files, start time will be previous day.
    ls /glade/p/cisl/dares/Observations/GPS/local-allsats-2019/${ym}/obs_seq.gpsro_${ymd} >> olist
    if [[ $ssymd != $ymd ]]; then
      ls /glade/p/cisl/dares/Observations/GPS/local-allsats-2019/${ssym}/obs_seq.gpsro_${ssymd} >> olist
    fi
  
  
    ## quikscat - named by day-of-year, 0Z to 0Z. 
    #ls /glade/p/cisl/dares/Observations/obsolete/QuikSCAT_24_subx2_ascii/${ym}/qscatL2B_${cyear}_${cdoy}_obs_seq.out >> olist
    # for 0Z files, start time will be previous day.
    #if [[ $ssymd != $ymd ]]; then
    #  ls /glade/p/cisl/dares/Observations/obsolete/QuikSCAT_24_subx2_ascii/${ssym}/qscatL2B_${ssyear}_${ssdoy}_obs_seq.out >> olist
    #fi
  
    ## AIRS - named by YYYYMMDD, 0Z to 0Z (granule 240 has scans from next day)
    # for 0Z files, start time will be previous day.  Last file of a day 
    # (granule 240) contains data for next day, but this gets taken care 
    # of since we are already including the previous day's data for 0Z.
    ls /glade/p/cisl/dares/Observations/AIRS/AIRS_24_sub9x10_nceperrs/${ym}/obs_seq.AIRS.${ymd}.out >> olist
    if [[ $ssymd != $ymd ]]; then
      ls /glade/p/cisl/dares/Observations/AIRS/AIRS_24_sub9x10_nceperrs/${ssym}/obs_seq.AIRS.${ssymd}.out >> olist
    fi
   
    # where to do the work.
    workdir=workdir_${ymdh}
  
    # if you want to change the naming convention for the output location,
    # change 'outdir' here and it will get changed in the template file.
  
    # one level deeper to account for cd'ing into workdir
    outdir=../../../NCEP+ACARS+GPS+AIRS/Thinned_x9x10/${ym}_6H_CESM
  
    sed -e "s/YYYY/${cyear}/g"       \
        -e "s/MM/${cmonth}/g"        \
        -e "s/DD/${cday}/g"          \
        -e "s/HH/${chour}/g"         \
        -e "s/GREG1/${ssgregday}/g"  \
        -e "s/GREG2/${ssgregsec}/g"  \
        -e "s/GREG3/${segregday}/g"  \
        -e "s/GREG4/${segregsec}/g"  \
        -e "s;OUTDIR;${outdir};g"    \
        -e "s/OUTTIME/${cesmtime}/g"  < ./input.nml.template > input.nml
  
    mkdir -p $workdir
    mv -f olist $workdir
    cp -f input.nml $workdir
    ( cd $workdir; ln -sf ../$EXEDIR/obs_sequence_tool . )
   
    # create a command file where each line calls a script with
    # unique arguments, including a unique work directory name.
    if [ "$SLURM" != "" ]; then
      let k=$j-1
      echo "$k ksh ./domerge.sh $workdir $outdir" >> mycmdfile
    else
      echo "ksh ./domerge.sh $workdir $outdir" >> mycmdfile
    fi
    # ----------------------------------------

    # advance the step; the output is YYYYMMDDHH
    curstep=$nextstep
    nextstep=`echo $curstep     $step | $EXEDIR/advance_time`
   stepstart=`echo $curstep $halfback | $EXEDIR/advance_time`
     stepend=`echo $curstep $halfstep | $EXEDIR/advance_time`
   
#echo bot of loop
#echo curstep nextstep stepstart stepend 
#echo $curstep $nextstep $stepstart $stepend 

    # advance the loop counter
    let s=$s+1
   
    # advance the concurrent job counter
    let j=$j+1
  done

  echo running jobs:
  cat mycmdfile

  # the system seems to want the same number of commands in each
  # invocation of the command file as there are cpus on the node.
  # if we aren't running an even multiple of real tasks compared
  # to the cpu count, pad the rest of the script with a call to 'date'

  # avoid echoing the filename by making wc read stdin
  let j=`cat mycmdfile | wc -l`
  let j=$j+1
  while [[ $j -le $njobs ]] ; do
    if [ "$SLURM" != "" ]; then
      let k=$j-1
      echo "$k date " >> mycmdfile
    else
      echo "date " >> mycmdfile
    fi
    let j=$j+1
  done

  # actually launch the jobs here
  $RUNCMD ./mycmdfile 

done


echo job ended at `date`

exit 0

# <next few lines under version control, do not edit>
# $URL: https://subversion.ucar.edu/DAReS/DART/trunk/observations/NCEP/prep_bufr/work/multi_parallel.lsf $
# $Revision: 9948 $
# $Date: 2016-03-03 15:30:57 -0700 (Thu, 03 Mar 2016) $

